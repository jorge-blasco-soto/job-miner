# JobMiner Architecture

## System Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         JOBMINER SYSTEM                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Trigger Source  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”œâ”€ Manual: poetry run jobminer
         â”œâ”€ Automated: GitHub Actions (daily 9 AM UTC)
         â””â”€ Docker: docker-compose up
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      JOB SCRAPER ORCHESTRATOR                    â”‚
â”‚                       (jobminer/scraper.py)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  STEP 1: Scrape from Multiple      â”‚
    â”‚          Job Sources               â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”œâ”€ RemoteOK API         â”€â”€â”€â”€â”€â”€> Public API (no auth)
         â”œâ”€ We Work Remotely     â”€â”€â”€â”€â”€â”€> Web scraping
         â”œâ”€ Remotive             â”€â”€â”€â”€â”€â”€> Web scraping
         â””â”€ Company Career Pages â”€â”€â”€â”€â”€â”€> Greenhouse/Lever boards
         â”‚
         â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  STEP 2: Filter by Company         â”‚
    â”‚          (80+ established cos)     â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚  Companies Database (jobminer/companies.py)
         â”‚  â”œâ”€ 200+ employees âœ“
         â”‚  â”œâ”€ 5+ years old âœ“
         â”‚  â”œâ”€ Stable growth âœ“
         â”‚  â””â”€ Tech-focused âœ“
         â”‚
         â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  STEP 3: Filter by Keywords        â”‚
    â”‚          & Remote Status           â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚  Target Roles:
         â”‚  â”œâ”€ Data Engineer
         â”‚  â”œâ”€ Senior Data Engineer
         â”‚  â”œâ”€ Software Engineer
         â”‚  â””â”€ Solutions Architect
         â”‚
         â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  STEP 4: Deduplicate by URL        â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  STEP 5: LLM Analysis & Scoring    â”‚
    â”‚          (jobminer/llm_filter.py)  â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”œâ”€ Ollama (Local) â”€â”€> llama2 model
         â”‚  â””â”€ FREE, runs locally
         â”‚
         â””â”€ OpenAI API (Optional) â”€â”€> gpt-3.5-turbo
            â””â”€ For cloud deployment
         â”‚
         â”‚  For each job:
         â”‚  â”œâ”€ Analyze description
         â”‚  â”œâ”€ Match to criteria
         â”‚  â”œâ”€ Generate score (0.0-1.0)
         â”‚  â””â”€ Write explanation
         â”‚
         â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  STEP 6: Filter by Score â‰¥ 0.5     â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  STEP 7: Merge with Existing       â”‚
    â”‚          (avoid duplicates)        â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  STEP 8: Save Results              â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”œâ”€ data/jobs_latest.json  (all jobs)
         â”œâ”€ data/jobs_latest.csv   (spreadsheet)
         â”œâ”€ data/jobs_TIMESTAMP.*  (historical)
         â””â”€ data/result_*.json     (metadata)
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         OUTPUT & DELIVERY                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”œâ”€ Local: Files in data/ directory
         â”œâ”€ GitHub: Auto-committed to repository
         â””â”€ Actions: Summary in GitHub UI
```

## Data Flow Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Job Sources â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”‚ Raw job listings
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Company Filter   â”‚ â—€â”€â”€â”€ â”‚ Company Database â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                   (80+ companies)
       â”‚ Filtered jobs
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Keyword Filter   â”‚ â—€â”€â”€â”€ â”‚ Target Roles     â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                   (config.py)
       â”‚ Matched jobs
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   LLM Analyzer   â”‚ â—€â”€â”€â”€ â”‚ Ollama / OpenAI  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                   (Local or Cloud)
       â”‚ Scored jobs
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Score Filter     â”‚
â”‚   (â‰¥ 0.5)        â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ Relevant jobs
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Deduplicator     â”‚ â—€â”€â”€â”€ â”‚ Existing Jobs    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                   (previous runs)
       â”‚ Unique jobs
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Storage Layer   â”‚
â”‚  - JSON          â”‚
â”‚  - CSV           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Component Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         JOBMINER PACKAGE                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

jobminer/
â”‚
â”œâ”€ main.py â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  â””â”€ Entry point, logging  â”‚
â”‚                            â–¼
â”œâ”€ config.py â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” Settings & Environment
â”‚  â””â”€ Pydantic settings         â”‚ - Target roles
â”‚                                â”‚ - Min employees/years
â”‚                                â”‚ - LLM config
â”‚                                â”‚ - Output format
â”‚                                â”‚
â”œâ”€ models.py â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ Data Models
â”‚  â”œâ”€ Job                        â”‚ - Job schema
â”‚  â”œâ”€ Company                    â”‚ - Company schema
â”‚  â””â”€ ScrapingResult             â”‚ - Result metadata
â”‚                                â”‚
â”œâ”€ companies.py â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ Company Database
â”‚  â”œâ”€ ESTABLISHED_COMPANIES      â”‚ - 80+ companies
â”‚  â”œâ”€ get_companies()            â”‚ - Lookup functions
â”‚  â””â”€ is_established_company()   â”‚ - Validation
â”‚                                â”‚
â”œâ”€ scrapers/ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ Scraping Module
â”‚  â”œâ”€ base.py                    â”‚ - BaseScraper class
â”‚  â”‚  â””â”€ Abstract scraper        â”‚ - Common methods
â”‚  â”‚                              â”‚
â”‚  â””â”€ job_boards.py              â”‚ - Implementations
â”‚     â”œâ”€ RemoteOKScraper         â”‚   - RemoteOK API
â”‚     â”œâ”€ WWRScraper              â”‚   - We Work Remotely
â”‚     â”œâ”€ RemotiveScraper         â”‚   - Remotive
â”‚     â””â”€ CompanyCareersPage      â”‚   - Greenhouse/Lever
â”‚                                â”‚
â”œâ”€ llm_filter.py â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ LLM Integration
â”‚  â”œâ”€ LLMFilter (base)           â”‚ - Base class
â”‚  â”œâ”€ OllamaFilter               â”‚ - Local Ollama
â”‚  â”œâ”€ OpenAICompatibleFilter     â”‚ - Cloud API
â”‚  â””â”€ get_llm_filter()           â”‚ - Factory
â”‚                                â”‚
â””â”€ scraper.py â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ Orchestration
   â””â”€ JobScraperOrchestrator     - Coordinates all steps
      â”œâ”€ run()                    - Main pipeline
      â”œâ”€ _deduplicate()           - Remove dupes
      â”œâ”€ _merge_with_existing()   - Merge data
      â””â”€ _save_jobs()             - Persist results
```

## Automation Flow (GitHub Actions)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     GITHUB ACTIONS WORKFLOW                      â”‚
â”‚                 (.github/workflows/scrape.yml)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Trigger:
  â”œâ”€ Schedule: Daily at 9 AM UTC (cron)
  â”œâ”€ Manual: workflow_dispatch
  â””â”€ Push: to main branch

Steps:
  â”‚
  1. Checkout code â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€> actions/checkout@v4
  â”‚
  2. Setup Python â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€> python 3.11
  â”‚
  3. Install Poetry â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€> snok/install-poetry
  â”‚
  4. Cache dependencies â”€â”€â”€â”€â”€â”€â”€> actions/cache (venv)
  â”‚
  5. Install dependencies â”€â”€â”€â”€â”€> poetry install
  â”‚
  6. Setup Ollama â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  â”œâ”€ Download & install      â”‚
  â”‚  â”œâ”€ Start service           â”‚
  â”‚  â””â”€ Pull llama2 model       â”‚
  â”‚                             â”‚
  7. Configure environment â”€â”€â”€â”€â”¤ Create .env
  â”‚                             â”‚
  8. Run scraper â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€> poetry run jobminer
  â”‚                             â”‚
  9. Commit results â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  â”œâ”€ Add data files          â”‚
  â”‚  â”œâ”€ Commit changes          â”‚
  â”‚  â””â”€ Push to repo            â”‚
  â”‚                             â”‚
 10. Upload artifacts â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  â”œâ”€ jobs_latest.json        â”‚
  â”‚  â”œâ”€ jobs_latest.csv         â”‚
  â”‚  â””â”€ jobminer.log            â”‚
  â”‚                             â”‚
 11. Create summary â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â””â”€ Show stats in UI        â”‚
        â”œâ”€ Total jobs           â”‚
        â”œâ”€ Top companies        â”‚
        â””â”€ Best matches         â”‚

Output:
  â”œâ”€ Committed to repository
  â”œâ”€ Artifacts (30 days)
  â””â”€ Visual summary
```

## Technology Stack

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        TECHNOLOGY STACK                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Language & Runtime:
  â”œâ”€ Python 3.10+
  â””â”€ Poetry (dependency management)

Web Scraping:
  â”œâ”€ requests (HTTP client)
  â”œâ”€ BeautifulSoup4 (HTML parsing)
  â””â”€ lxml (XML/HTML parser)

Data Processing:
  â”œâ”€ Pydantic (data validation)
  â”œâ”€ Pydantic Settings (config)
  â””â”€ JSON/CSV (storage)

LLM Integration:
  â”œâ”€ Ollama (local, FREE)
  â”‚  â””â”€ llama2, mistral, codellama
  â””â”€ OpenAI SDK (cloud, optional)
     â””â”€ gpt-3.5-turbo, gpt-4

Automation:
  â”œâ”€ GitHub Actions (CI/CD)
  â””â”€ Cron scheduling

Containerization:
  â”œâ”€ Docker
  â””â”€ Docker Compose

Development:
  â”œâ”€ Black (formatting)
  â”œâ”€ flake8 (linting)
  â”œâ”€ mypy (type checking)
  â””â”€ pytest (testing)

All 100% FREE & Open Source! ğŸ‰
```

## Deployment Options

```
Option 1: GitHub Actions (Recommended)
  âœ… Completely automated
  âœ… Free (2,000 min/month)
  âœ… Results auto-committed
  âœ… No server needed
  âŒ Slower LLM (runs in cloud)

Option 2: Local Execution
  âœ… Fast LLM (local Ollama)
  âœ… Immediate results
  âœ… Full control
  âŒ Manual execution
  âŒ Requires local setup

Option 3: Docker
  âœ… Consistent environment
  âœ… Easy setup
  âœ… Portable
  âŒ Requires Docker installed
  âŒ More resource intensive

Choose based on your needs!
```
